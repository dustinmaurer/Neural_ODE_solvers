{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward ODE system\n",
    "def system(y, t, matrix):\n",
    "    row_sums = np.sum(matrix, axis=1)\n",
    "    shapes = 1 / (1 + np.exp(row_sums))\n",
    "    dydt = shapes - y\n",
    "    return dydt\n",
    "\n",
    "# Jacobian of the system w.r.t. y (df/dy)\n",
    "def jacobian(y, t, matrix):\n",
    "    # df[i]/dy[j] = -1 if i == j, 0 otherwise (since dydt[i] = shapes[i] - y[i])\n",
    "    return -np.eye(len(y))\n",
    "\n",
    "# Adjoint ODE system (dλ/dt = -λ * df/dy)\n",
    "def adjoint_system(lmbda, t, y_trajectory, t_forward, matrix):\n",
    "    # Interpolate y at current t (since adjoint runs backward)\n",
    "    y = np.interp(t, t_forward, y_trajectory[:, 0]), np.interp(t, t_forward, y_trajectory[:, 1]), np.interp(t, t_forward, y_trajectory[:, 2])\n",
    "    y = np.array(y)\n",
    "    J = jacobian(y, t, matrix)\n",
    "    dlmbda_dt = -np.dot(lmbda, J)  # dλ/dt = -λ * df/dy\n",
    "    return dlmbda_dt\n",
    "\n",
    "# Gradient of f w.r.t. matrix (df/d(matrix))\n",
    "def gradient_f_wrt_matrix(y, t, matrix):\n",
    "    row_sums = np.sum(matrix, axis=1)\n",
    "    z = 1 / (1 + np.exp(row_sums))\n",
    "    dz_dsum = z * (1 - z)  # Sigmoid derivative\n",
    "    grad = np.zeros_like(matrix)\n",
    "    for i in range(matrix.shape[0]):\n",
    "        grad[i, :] = dz_dsum[i]  # Each element in row i contributes equally to sum\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution at t = 1: [0.0642039  0.07460741 0.33117453]\n",
      "Iteration 0: MSE = 0.194002\n",
      "Solution at t = 1: [0.49992984 0.69972176 0.30000307]\n",
      "Iteration 20: MSE = 0.000000\n",
      "\n",
      "Final Results:\n",
      "Optimized matrix:\n",
      "[[ 0.71650161 -0.64739352 -0.06881275]\n",
      " [ 0.9152008   0.5418656  -2.30297027]\n",
      " [ 1.00067846 -0.10076717 -0.05262881]]\n",
      "Solution at t = 1: [0.49992984 0.69972176 0.30000307]\n",
      "Target values: [0.5 0.7 0.3]\n",
      "Final MSE: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "np.random.seed(0)\n",
    "matrix = np.random.normal(size=(3, 3))\n",
    "\n",
    "n = matrix.shape[0]\n",
    "y0 = np.array([0.5, 0.7, 0.3])\n",
    "stop_time = 3\n",
    "t = np.linspace(0, stop_time, 101)\n",
    "target_values = np.array([0.5, 0.7, 0.3])\n",
    "\n",
    "learning_rate = 1\n",
    "max_iterations = 200\n",
    "mse_target = 0.001\n",
    "\n",
    "# Optimization loop\n",
    "for iteration in range(max_iterations):\n",
    "    # 1. Solve forward ODE\n",
    "    solution = odeint(system, y0, t, args=(matrix,))\n",
    "    solution_at_t1 = solution[-1]\n",
    "    mse = np.mean((solution_at_t1 - target_values)**2)\n",
    "\n",
    "    if iteration % 20 == 0:\n",
    "        print(f\"Solution at t = 1: {solution_at_t1}\")\n",
    "        print(f\"Iteration {iteration}: MSE = {mse:.6f}\")\n",
    "        if mse < mse_target:\n",
    "            break\n",
    "\n",
    "    # 2. Solve adjoint ODE backward\n",
    "    lambda0 = solution_at_t1 - target_values  # Initial condition: dL/dy(1)\n",
    "    t_backward = t[::-1]  # Reverse time from 1 to 0\n",
    "    adjoint_solution = odeint(adjoint_system, lambda0, t_backward, args=(solution, t, matrix))\n",
    "\n",
    "    # Reverse adjoint solution to match forward time\n",
    "    lambda_t = adjoint_solution[::-1]\n",
    "\n",
    "    # 3. Compute gradient w.r.t. matrix\n",
    "    gradient_matrix = np.zeros_like(matrix)\n",
    "    dt = t[stop_time] - t[0]\n",
    "    for k in range(len(t)):\n",
    "        grad_f = gradient_f_wrt_matrix(solution[k], t[k], matrix)\n",
    "        for i in range(n):\n",
    "            gradient_matrix[i, :] += lambda_t[k][i] * grad_f[i, :] * dt  # Integrate λ * df/d(matrix)\n",
    "\n",
    "    # Update matrix\n",
    "    matrix += learning_rate * gradient_matrix\n",
    "\n",
    "# Final results\n",
    "solution_final = odeint(system, y0, t, args=(matrix,))\n",
    "final_at_t1 = solution_final[-1]\n",
    "\n",
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Optimized matrix:\\n{matrix}\")\n",
    "print(f\"Solution at t = 1: {final_at_t1}\")\n",
    "print(f\"Target values: {target_values}\")\n",
    "print(f\"Final MSE: {np.mean((final_at_t1 - target_values)**2):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
